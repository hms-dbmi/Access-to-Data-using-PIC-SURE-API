{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite\n",
    "- python 3.6 or later\n",
    "- pip python package manager, already available in most systems with a python interpreter installed ([pip installation instructions](https://pip.pypa.io/en/stable/installing/))\n",
    "\n",
    "Demographics_PICSURE_API_validations.ipynb\n",
    "\n",
    "data_medications_nodes_from_db.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages installation\n",
    "\n",
    "Installation of the packages listed in the `requirements.txt` file, as well as the two components of the PIC-SURE API from GitHub, that is the PIC-SURE adapter and the PIC-SURE Client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the external dependencies, as well as user-defined functions stored in the `python_lib` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "\n",
    "#from python_lib.utils import get_multiIndex_variablesDict, joining_variablesDict_onCol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting the display parameter for tables and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"max.rows\", 100)\n",
    "\n",
    "# Matplotlib display parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (14,8)\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a PIC-SURE resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several information are required to get access to data through the PIC-SURE API: a network URL, a resource id, and a user-specific security token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://precisionlink-biobank4discovery.childrens.harvard.edu/picsure/\"\n",
    "resource_id = \"6aa47730-3288-4c45-bfa1-5a8730666016\"\n",
    "token_file = \"token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, my_token, True)\n",
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two objects are created here: a `connection` and a `resource` object.\n",
    "\n",
    "As we will only be using one single resource, **the `resource` object is actually the only one we will need to proceed with data analysis hereafter**. \n",
    "\n",
    "It is connected to the specific data source ID we specified, and enables to query and retrieve data from this database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#File data_medications_nodes_from_db.csv is generated from database with node_name, variable_name and patient_counts for all the categorical values under Medications node. And compared to the counts in HPDS for these variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"COUNTS\",\"CONCEPT_PATH\",\"TVAL_CHAR\",\"NVAL_NUM\"\n",
    "#Processing file 1\n",
    "import time\n",
    "print('********  Start processing \\Medications\\ *********' ) \n",
    "dfdb_node = pd.read_csv('Med_Data_Ext_1.csv' )\n",
    "dfdb_node_sort = dfdb_node.sort_values(by=[\"CONCEPT_PATH\",\"TVAL_CHAR\"])\n",
    "\n",
    "f = open(\"MedicationsError_1.txt\", \"a\")\n",
    "for i in range(len(dfdb_node_sort)):\n",
    "    try:\n",
    "        counts = dfdb_node_sort['COUNTS'].iloc[i]\n",
    "        concept_path =  dfdb_node_sort['CONCEPT_PATH'].iloc[i] \n",
    "        tval_char =  dfdb_node_sort['TVAL_CHAR'].iloc[i] \n",
    "        my_query = resource.query()\n",
    "        my_query.filter().add(concept_path,tval_char)\n",
    "        print( 'Processing '+ concept_path+tval_char )\n",
    "        my_count = my_query.getCount() \n",
    "        if ( my_count != counts ):\n",
    "            print( concept_path +'  '+ tval_char  +'counts not match  - Actual counts '+ str(my_count) , '<>  DB count ' + str(counts) )\n",
    "        else:\n",
    "            print( concept_path +'  '+ tval_char  +'- Actual counts '+ str(my_count) , ' = DB count ' + str(counts) )\n",
    "    \n",
    "    except:  \n",
    "        f.write(\"Errored Row concept_path - \" + concept_path + \" tval_char \" + tval_char + \"\\n\")\n",
    "        continue\n",
    "f.close()\n",
    "print('********  End processing \\Medications\\ *********' )     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"COUNTS\",\"CONCEPT_PATH\",\"TVAL_CHAR\",\"NVAL_NUM\"\n",
    "#Processing file 2\n",
    "import time\n",
    "print('********  Start processing \\Medications\\Any Nodes *********' )\n",
    "dfdb_node = pd.read_csv('Med_Data_Ext_2.csv' )\n",
    "dfdb_node_sort = dfdb_node.sort_values(by=[\"CONCEPT_PATH\",\"TVAL_CHAR\"])\n",
    "\n",
    "f = open(\"MedicationsError_2.txt\", \"a\")\n",
    "for i in range(len(dfdb_node_sort)):\n",
    "    try:\n",
    "        counts = dfdb_node_sort['COUNTS'].iloc[i]\n",
    "        concept_path =  dfdb_node_sort['CONCEPT_PATH'].iloc[i] \n",
    "        tval_char =  dfdb_node_sort['TVAL_CHAR'].iloc[i] \n",
    "        my_query = resource.query()\n",
    "        my_query.filter().add(concept_path,tval_char)\n",
    "        print( 'Processing '+ concept_path+tval_char )\n",
    "        my_count = my_query.getCount() \n",
    "        if ( my_count != counts ):\n",
    "            print( concept_path +'  '+ tval_char  +'counts not match  - Actual counts '+ str(my_count) , '<>  DB count ' + str(counts) )\n",
    "        else:\n",
    "            print( concept_path +'  '+ tval_char  +'- Actual counts '+ str(my_count) , ' = DB count ' + str(counts) )\n",
    "    \n",
    "    except:  \n",
    "        f.write(\"Errored Row concept_path - \" + concept_path + \" tval_char \" + tval_char + \"\\n\")\n",
    "        continue\n",
    "f.close()\n",
    "print('********  End processing \\Medications\\Any Nodes *********' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
