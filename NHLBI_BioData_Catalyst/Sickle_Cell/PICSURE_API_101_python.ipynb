{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIC-SURE API use-case: quick analysis on CIBMTR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial notebook aimed to get the user quickly up and running with the python PIC-SURE API. It covers the main functionalities of the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIC-SURE python API \n",
    "### What is PIC-SURE? \n",
    "\n",
    "As part of the BioData Catalyst initiative, the Patient Information Commons Standard Unification of Research Elements (PIC-SURE) platform has been integrating clinical and genomic datasets from multiple TOPMed and TOPMed related studies funded by the National Heart Lung and Blood Institute (NHLBI). \n",
    "\n",
    "Original data exposed through the PIC-SURE API encompasses a large heterogeneity of data organization underneath. PIC-SURE hides this complexity and exposes the different study datasets in a single tabular format. By simplifying the process of data extraction, it allows investigators to focus on downstream analysis and to facilitate reproducible science.\n",
    "\n",
    "### More about PIC-SURE\n",
    "The API is available in two different programming languages, python and R, enabling investigators to query the databases the same way using either language.\n",
    "\n",
    "PIC-SURE is a larger project from which the R/python PIC-SURE API is only a brick. Among other things, PIC-SURE also offers a graphical user interface that allows researchers to explore variables across multiple studies, filter patients that match criteria, and create cohorts from this interactive exploration.\n",
    "\n",
    "The python API is actively developed by the Avillach Lab at Harvard Medical School.\n",
    "\n",
    "PIC-SURE API GitHub repo:\n",
    "* https://github.com/hms-dbmi/pic-sure-python-adapter-hpds\n",
    "* https://github.com/hms-dbmi/pic-sure-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " -------   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting your own user-specific security token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure to review the \"Get your security token\" documentation, which exists in the NHLBI_BioData_Catalyst [README.md file](https://github.com/hms-dbmi/Access-to-Data-using-PIC-SURE-API/tree/master/NHLBI_BioData_Catalyst#get-your-security-token). It explains about how to get a security token, which is mandatory to access the databases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-requisite\n",
    "- python 3.6 or later\n",
    "- pip: python package manager, already available in most system with a python interpreter installed ([pip installation instructions](https://pip.pypa.io/en/stable/installing/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPython Magic command\n",
    "\n",
    "The following code loads the `autoreload` IPython extension. Although `autoreload` is not necessary to execute the rest of the notebook, it enables the notebook to reload every dependency each time python code is executed.  This will allow the notebook to take into account changes in imported external files, such as the user defined functions stored in separate file, without needing to manually reload libraries. This is helpful when developing interactively. Learn more about [IPython Magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages\n",
    "\n",
    "Install the following:\n",
    "* packages listed in the `requirements.txt` file (listed below, along with verison numbers)\n",
    "* PIC-SURE API components (from GitHub)\n",
    "    * PIC-SURE Adapter\n",
    "    * PIC-SURE Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the external dependencies and user-defined functions stored in the `python_lib` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureClient\n",
    "import PicSureBdcAdapter\n",
    "\n",
    "from python_lib.utils import get_multiIndex_variablesDict, get_dic_renaming_vars, joining_variablesDict_onCol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set the display parameters for tables and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"max.rows\", 100)\n",
    "\n",
    "# Matplotlib parameters options\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Prints: [8.0, 6.0]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 8\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a PIC-SURE resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is required to get access to data through the PIC-SURE API: \n",
    "- a network URL\n",
    "- a resource id, and \n",
    "- a user-specific security token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not already retrieved your user-specific token, please refer to the \"Get your security token\" section of the [README.md](https://github.com/hms-dbmi/Access-to-Data-using-PIC-SURE-API/tree/master/NHLBI_BioData_Catalyst#get-your-security-token) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://biodatacatalyst.integration.hms.harvard.edu/picsure\"\n",
    "#PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "token_file = \"token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, my_token, True)\n",
    "adapter = PicSureBdcAdapter.Adapter(connection)\n",
    "resource = adapter.useResource(resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two objects are created here: a `connection` and a `resource` object.\n",
    "\n",
    "Since will only be using a single resource, **the `resource` object is actually the only one we will need to proceed with data analysis hereafter**. \n",
    "\n",
    "It is connected to the specific data source ID we specified and enables us to query and retrieve data from this database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting help with the PIC-SURE python API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each object exposed by the PicSureBdcHpds library has a `help()` method. Calling it without parameters will print out  information about functionalities of this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, this output tells us that this `resource` object has 3 methods and provides a quick definition of those methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the *variables dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a connection to the desired resource has been established, we first need to understand which variables are available in the database. We will use the `dictionary` method of the `resource` object to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `dictionary` instance enables us to retrieve matching records by searching for a specific term, or to retrieve information about all the available variables, using the `find()` method. For instance, looking for variables containing the term `Sex` in their names is done this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = resource.dictionary()\n",
    "dictionary_search = dictionary.find(\"Sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects created by the `dictionary.find` method can expose the search results using 4 different methods: `.count()`, `.keys()`, `.entries()`, and `.DataFrame()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint({\"Count\": dictionary_search.count(), \n",
    "        \"Keys\": dictionary_search.keys()[0:3],\n",
    "        \"Entries\": dictionary_search.entries()[0:3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary_search.DataFrame().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The `.DataFrame()` method enables us to get the result of the dictionary search in a pandas DataFrame format. This way, it allows us to:** \n",
    "\n",
    "\n",
    "* Use the various information exposed in the dictionary (patient count, variable type ...) as criteria for variable selection.\n",
    "* Use the row names of the DataFrame to get the actual variable names to be used in the query, as shown below.\n",
    "\n",
    "Variable names aren't very pratical to use right away for two reasons:\n",
    "1. Very long\n",
    "2. Presence of backslashes that prevent copy-pasting. \n",
    "\n",
    "However, retrieving the dictionary search result in the form of a dataframe can help access the variable names. Let's say we want to retrieve every variable from the HCT for SCD dataset in the form of a DataFrame. We can do this using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict = resource.dictionary().find(\"HCT for SCD\").DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_variablesDict.iloc[10:20,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `dictionary.find()` function without arguments returns every entry, as shown in the help documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource.dictionary().help()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary currently returned by the API provides information about the variables, such as:\n",
    "- observationCount: number of entries with non-null value\n",
    "- categorical: type of the variables, True if strings, False if numerical\n",
    "- min/max: only provided for numerical variables\n",
    "- HpdsDataType: 'phenotypes' or 'genotypes'. Currently, the API only expsoses'phenotypes' variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export full data dictionary to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to export the data dictionary first we will create a Pandas dataframe called `fullVariableDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVariableDict = resource.dictionary().find().DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that `fullVariableDict` dataframe contains some values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVariableDict.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullVariableDict.to_csv('data_dictionary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see a `data_dictionary.csv` in the Jupyter Hub file explorer, in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable dictionary + pandas multiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple user-defined function (`get_multiIndex_variablesDict`) to add a little more information to the variable dictionary and to simplify working with variables names. It takes advantage of pandas MultiIndex functionality [see pandas official documentation on this topic](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html).\n",
    "\n",
    "Although not an official feature of the API, such functionality illustrates how to quickly select groups of related variables.\n",
    "\n",
    "Printing the multiIndexed variable Dictionary allows us to quickly see the tree-like organization of the variable names. Moreover, original and simplified variable names are now stored respectively in the `name` and `simplified_name` columns (simplified variable names is simply the last component of the variable name, which is usually the most informative to let us know what each variable is about)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict = get_multiIndex_variablesDict(plain_variablesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variablesDict.loc[[\"Hematopoietic Cell Transplant for Sickle Cell Disease (HCT for SCD) ( phs002385 )\"],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the number of lines to be displayed for the future outputs\n",
    "pd.set_option(\"max.rows\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a simple example to illustrate the ease of use a multiIndex dictionary. Let's say we are interested in the variables within the \"5 - CRF data collection track only\" of the \"Hematopoietic Cell Transplant for Sickle Cell Disease (HCT for SCD) ( phs002385 )\" study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_study = variablesDict.index.get_level_values(0) == \"Hematopoietic Cell Transplant for Sickle Cell Disease (HCT for SCD) ( phs002385 )\"\n",
    "mask_dctrack = variablesDict.index.get_level_values(1) == \"5 - CRF data collection track only\"\n",
    "dctrack_variables = variablesDict.loc[mask_study & mask_dctrack,:]\n",
    "dctrack_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple filter can be easily combined with other filters to quickly select variables of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying and retrieving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second cornerstone of the API is the `query` object. It is how we retrieve data from the resource."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a query object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_query = resource.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query object has several methods that enable us to build a query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method | Arguments / Input | Output|\n",
    "|--------|-------------------|-------|\n",
    "| query.select.add() | variable names (string) or list of strings | all variables included in the list (no record subsetting)|\n",
    "| query.require.add() | variable names (string) or list of strings | all variables; only records that do not contain null values for input variables |\n",
    "| query.anyof.add() | variable names (string) or list of strings | all variables; only records that contain at least one non-null value for input variables |\n",
    "| query.filter.add() | variable name and additional filtering values | input variable; only records that match filter criteria |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 4 methods can be combined when building a query. The record eventually returned by the query has to meet all the different specified filters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we are interested in the age at which patients from the following cohort received their transplant:\n",
    "* males\n",
    "* patients with avascular necrosis\n",
    "* patients that received their transplant after the year 1999\n",
    "\n",
    "First we will find variables pertaining to sex and avascular necrosis. We can do this by searching for \"Sex\" and \"Avascular necrosis\" in the `simplified_name` column of `variablesDict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_var = variablesDict.loc[variablesDict[\"simplified_name\"] == \"Sex\", \"name\"].values[0]\n",
    "avascular_necrosis_varname = variablesDict.loc[variablesDict[\"simplified_name\"] == \"Avascular necrosis\", \"name\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peek at the result for avascular necrosis\n",
    "variablesDict.loc[variablesDict[\"simplified_name\"] == \"Avascular necrosis\", \"name\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can find the variable pertaining to \"Year of transplant\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_transplant_varname = variablesDict.loc[variablesDict[\"simplified_name\"] == \"Year of transplant\", \"name\"].values[0]\n",
    "yr_transplant_varname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new query and apply our filters to retrieve the cohort of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients with avascular necrosis\n",
    "my_query.select().add(avascular_necrosis_varname)\n",
    "my_query.filter().add(avascular_necrosis_varname, \"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Males\n",
    "my_query.select().add(sex_var)\n",
    "my_query.filter().add(sex_var, \"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients receiving transplants after 1999\n",
    "my_query.select().add(yr_transplant_varname)\n",
    "my_query.filter().add(yr_transplant_varname, min=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this cohort, we can add the variable of interest: \"Patient age at transplant, years\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_transplant_var = variablesDict.loc[variablesDict[\"simplified_name\"] == \"Patient age at transplant, years\", \"name\"].values[0]\n",
    "my_query.select().add(age_transplant_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our query object is finally built, we use the `query.run()` function to retrieve the data corresponding to our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = my_query.getResultsDataFrame().set_index(\"Patient ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been retrieved as a dataframe, you can use python functions to conduct analyses and create visualizations, such as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[age_transplant_var].plot.hist(legend=None, \n",
    "                                       title= \"Age when transplant received in males with arrhythmia from 2000 to present\", \n",
    "                                       bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
