{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIC-SURE python API use-case: Phenome-Wide analysis on BioData Catalyst studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an illustration example about how to query data using the python **PIC-SURE API**. It takes as use-case a simple PheWAS analysis. This notebook is intentionally straightforward, and explanation provided are only aimed at guiding through the PheWAS analysis process. For a more step-by-step introduction to the python PIC-SURE API, see the `1_PICSURE_API_101.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure to get a user-specific security token. For more information on how to proceed, see the `get_your_token.ipynb` notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System requirements\n",
    "- Python 3.6 or later\n",
    "- pip package manager\n",
    "- bash interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of external dependencies\n",
    "**Note that if you are using the dedicated PIC-SURE environment within the BioData Catalyst Seven Bridges platform, the necessary packages have already been installed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "### Uncomment this code if you are not using the PIC-SURE environment in Seven Bridges, or if you do not have all the necessary dependencies installed.\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing latest python PIC-SURE API libraries from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import PicSureClient\n",
    "import PicSureBdcAdapter\n",
    "\n",
    "from python_lib.utils import get_multiIndex_variablesDict, joining_variablesDict_onCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"NB: This Jupyter Notebook has been written using PIC-SURE API following versions:\\n- PicSureBdcAdapter: 1.0.0\\n- PicSureClient: 1.1.0\")\n",
    "print(\"The installed PIC-SURE API libraries versions:\\n- PicSureBdcAdapter: {0}\\n- PicSureClient: {1}\".format(PicSureBdcAdapter.__version__, PicSureClient.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "# Matplotlib display parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (14,8)\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to a PIC-SURE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "resource_id = \"02e23f52-f354-4e8b-992c-d37c8b9ba140\"\n",
    "token_file = \"token.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "client = PicSureClient.Client()\n",
    "connection = client.connect(PICSURE_network_URL, my_token)\n",
    "adapter = PicSureBdcAdapter.Adapter(connection)\n",
    "resource = adapter.useResource(resource_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PheWAS analysis\n",
    "*Note: This example is not meant to be publication-ready, but rather serve as a guide or starting point to perform PheWAS.*\n",
    "\n",
    "This PheWAS analysis focuses on the TopMed DCC Harmonized Variables. \n",
    "We leverage the harmonized variables to provide an example PheWAS focused on total cholesterol in FHS.\n",
    "The PIC-SURE API is helpful in wrangling our phenotypic data. \n",
    "\n",
    "In a nutshell, this PheWAS analysis follows the subsequent steps:\n",
    "1. Retrieving the variable dictionary, using the PIC-SURE API dedicated methods\n",
    "2. Using the PIC-SURE API to select variables and retrieve data\n",
    "3. Data management\n",
    "4. Statistical analysis for each study and sex\n",
    "5. Visualization of results in Manhattan Plot\n",
    "\n",
    "With this, we are tackling two different analysis considerations of a PheWAS: \n",
    "1. Using multiple variables in a PheWAS. In this example, we are looking into sex differences of total cholesterol\n",
    "2. Harmonization and meta-analysis issues when using data from multiple studies or datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieving variable dictionary from PIC-SURE\n",
    "The first step to conducting the PheWAS is to retrieve information about the variables that will be used in the analysis. For this example, we will be using variables from the TOPMed Data Coordinating Center (DCC) Harmonized data set. \n",
    "\n",
    "The Data Harmonization effort aims to produce \"a high quality, lasting resource of publicly available and thoroughly documented harmonized phenotype variables\". The TOPMed DCC collaborates with Working Group members and phenotype experts on this endeavour. So far, 44 harmonized variables are accessible through PIC-SURE API (in addition to the age at which each variable value has been collected for a given subject).\n",
    "\n",
    "Which phenotypic characteristics are included in the harmonized variables?\n",
    "\n",
    "- Key NHLBI phenotypes\n",
    "    - Blood cell counts\n",
    "    - VTE\n",
    "    - Atherosclerosis-related phenotypes\n",
    "    - Lipids\n",
    "    - Blood pressure\n",
    "    \n",
    "    \n",
    "- Common covariates\n",
    "    - Height\n",
    "    - Weight\n",
    "    - BMI\n",
    "    - Smoking status\n",
    "    - Race/ethnicity\n",
    "\n",
    "More information about the variable harmonization process is available at https://www.nhlbiwgs.org/sites/default/files/pheno_harmonization_guidelines.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we retrieve the harmonized variables information by searching for `DCC Harmonized data set` in PIC-SURE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "harmonized_variables = resource.dictionary().find(\"DCC Harmonized data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized_dic = harmonized_variables.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Display the variables tree hierarchy from the variables name\n",
    "variablesDict = get_multiIndex_variablesDict(harmonized_dic)\n",
    "variablesDict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we retrieved 80 variables from the DCC harmonized data set. The structure of `variablesDict` allows us to visualize the tree-like structure of the concept paths more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using the PIC-SURE API to select variables and retrieve data\n",
    "Now that we've retrieved the variable information, we need to select our variable of interest. In this example, we are interested in exploring the relationship between the harmonized variables and blood cholesterol. Specifically, we will find the full concept path that contains \"Blood mass concentration of total cholesterol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_harmonized_dic = harmonized_variables.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the dependent variable - total cholesterol\n",
    "cholesterol_path = my_harmonized_dic.filter(like = 'Blood mass concentration of total cholesterol', axis = 0)\n",
    "cholesterol_path = list(cholesterol_path.index)[0]\n",
    "cholesterol_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full list of concept paths with cholesterol_path removed\n",
    "selected_vars = list(variablesDict['name'])\n",
    "selected_vars.remove(cholesterol_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to create our query and retrieve the dataframe. This query will consist of two parts:\n",
    "1. **Any record of `cholesterol_path`.** By performing an \"any record of\" filter on the `cholesterol_path`, we will filter out all participants that do not have total blood cholesterol measurements. This allows us to perform more meaningful statistical analysis on the data.\n",
    "2. **Select all remaining harmonized variables.** We will then add all of the remaining harmonized variables to the query, which will allow us to retrieve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a query\n",
    "query = resource.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.anyof().add(cholesterol_path) # Use anyof for the cholesterol variable to filter out the NA values\n",
    "query.select().add(selected_vars)\n",
    "facts = query.getResultsDataFrame(low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data-management\n",
    "Now that we have retrieved the data, we shall perform some data management steps to prepare for the statistical analysis. First, we will identify which variables are categorical and which are continuous using the \"categorical\" column of the `facts` dataframe. This is an example of how the PIC-SURE API greatly simplifies this step for the user, as categorizing variables can be tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_varnames = my_harmonized_dic[my_harmonized_dic.categorical == True]\n",
    "categorical_varnames = list(categorical_varnames.index)\n",
    "\n",
    "continuous_varnames = my_harmonized_dic[my_harmonized_dic.categorical == False]\n",
    "continuous_varnames = list(continuous_varnames.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cholesterol_path from continuous_varnames\n",
    "continuous_varnames.remove(cholesterol_path) \n",
    "# remove subgroup concept path from categorical_varnames\n",
    "categorical_varnames.remove(\"\\\\DCC Harmonized data set\\\\01 - Demographics\\\\A distinct subgroup within a study  generally indicating subjects who share similar characteristics due to study design. Subjects may belong to only one subcohort.\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "To perform this PheWAS, we will frame two participant cohorts in the context of the dependent variable of interest. In this example, we are interested in blood cholesterol. However, `Blood mass concentation of total cholesterol` is a continuous variable. We shall convert this variable into a binary variable with two groups, Normal/Low and High cholesterol levels, by applying a [threshold of 200mg/dL](https://www.mayoclinic.org/diseases-conditions/high-blood-cholesterol/diagnosis-treatment/drc-20350806). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    list(facts[cholesterol_path] <= 200),\n",
    "    list(facts[cholesterol_path] > 200)\n",
    "]\n",
    "outputs = [0, 1] \n",
    "# Note: 0 indicates Normal/Low blood pressure, while 1 indicates High blood pressue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.select(conditions, outputs)\n",
    "facts['categorical_cholesterol'] = pd.Series(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also specify the variable name for the covariate we are interested in, in this case Sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_path = list(facts.filter(regex = 'sex'))[0]\n",
    "sex_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also select our cohorts of interest. In this example, we are interested in participants from the Framingham Heart Study (FHS) and the Atherosclerosis Risk In Communities (ARIC) cohort. We can utilize the `A distinct subgroup within a study  generally indicating subjects who share similar characteristics due to study design. Subjects may belong to only one subcohort.` concept path in the DCC Harmonized data set to select the participants of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_varnames = my_harmonized_dic[my_harmonized_dic.categorical == True]\n",
    "categorical_varnames = list(categorical_varnames.index)\n",
    "\n",
    "continuous_varnames = my_harmonized_dic[my_harmonized_dic.categorical == False]\n",
    "continuous_varnames = list(continuous_varnames.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts['FHS_cohort'] = facts.iloc[:,1].str.contains('FHS')\n",
    "facts['ARIC_cohort'] = facts.iloc[:,1].str.contains('ARIC')\n",
    "\n",
    "fhs_subset = facts[facts.FHS_cohort == True]\n",
    "aric_subset = facts[facts.ARIC_cohort == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Statistical analysis\n",
    "Two different association tests will be carried out according to variables data types:\n",
    "- Logistic regression for continuous variables, using the `Logit` statsmodels function\n",
    "- Fisher exact test for categorical variables, using the `chi2_contingency` scipy.stats function\n",
    "\n",
    "We will create two functions, `test_continuous` and `test_categorical`, to perform these statistical tests. \n",
    "An additional function, `check_vars`, will be used to check if the data passes some assumptions of these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sm\n",
    "import statistics\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.stats.multitest as smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_continuous(dependent_vec, independent_vec):\n",
    "    model = sm.Logit(dependent_vec, independent_vec, missing='drop')\n",
    "    pval = model.fit().pvalues[0]\n",
    "    return(pval)\n",
    "\n",
    "def test_categorical(dependent_vec, independent_vec):\n",
    "    contingency_table = pd.crosstab(index=dependent_vec, columns=independent_vec)\n",
    "    pval = chi2_contingency(contingency_table)[1]\n",
    "    return pval\n",
    "\n",
    "def check_vars(dependent_var, other_var, df, case_value, control_value):\n",
    "    check_pass = False\n",
    "    concept_vec = df.iloc[:,1].value_counts()\n",
    "    if len(concept_vec) > 1:\n",
    "        check_pass = True\n",
    "    return check_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the previously created functions into one broad analysis function: ```run_phewas```. This would allow the user to run a variation of the analyses described here simply by modifying the calls to the function. The arguments are described below.\n",
    "- `facts`: a dataframe representing the results from your PIC-SURE query. This dataframe can be filtered as needed.\n",
    "- `dependent_var`: the column name corresponding to the name of your outcome varible. In this example. 'categorical_cholesterol'.\n",
    "- `continuous_varnames`: a vector containing all column names of continuous variables within the facts dataframe which you would like to test.\n",
    "- `categorical_varnames`: a vector containing all column names of categorical variables within the facts dataframe which you would like to test.\n",
    "- `case_value`: the value corresponding to the 'cases' in the dependent_var vector\n",
    "- `control_value`: the value corresponding to the 'controls' in the dependent_var vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phewas(facts, dependent_var, continuous_varnames, categorical_varnames, case_value, control_value):\n",
    "    results_df = pd.DataFrame(columns=['concept_code', \n",
    "                                       'simplified_varname', \n",
    "                                       'vartype',\n",
    "                                       'pval',\n",
    "                                       'n_cases',\n",
    "                                       'n_controls',\n",
    "                                       'var_cases',\n",
    "                                       'var_controls'\n",
    "                                      ])\n",
    "    \n",
    "    for other_var in continuous_varnames:\n",
    "        df = facts[[dependent_var, other_var]]\n",
    "        check_pass = check_vars(dependent_var, other_var, df, case_value, control_value)\n",
    "        if check_pass:\n",
    "            cases = df[df.iloc[:,0]==case_value]\n",
    "            controls = df[df.iloc[:,0]==control_value]\n",
    "            row_to_add = [other_var, # concept_code\n",
    "                          other_var.split('\\\\')[-2], #simplified_varname\n",
    "                          'continuous', #vartype\n",
    "                          test_continuous(df.iloc[:,0], df.iloc[:,1]), #pval\n",
    "                          len(cases), #n_cases\n",
    "                          len(controls), #n_controls\n",
    "                          statistics.variance(cases.iloc[:,1].dropna()), #var_cases\n",
    "                          statistics.variance(controls.iloc[:,1].dropna()) #var_controls\n",
    "                         ]\n",
    "            results_df = results_df.append(pd.Series(row_to_add, index=results_df.columns), ignore_index=True)\n",
    "            \n",
    "    for other_var in categorical_varnames:\n",
    "        df = facts[[dependent_var, other_var]]\n",
    "        check_pass = check_vars(dependent_var, other_var, df, case_value, control_value)\n",
    "        if check_pass:\n",
    "            row_to_add = [other_var, #concept_code\n",
    "                          other_var.split('\\\\')[-2], #simplified_varname\n",
    "                          'categorical', #vartype\n",
    "                          test_categorical(df.iloc[:,0], df.iloc[:,1]), #pval\n",
    "                          len(df[df.iloc[:,0]==case_value]), #n_cases\n",
    "                          len(df[df.iloc[:,0]==control_value]), #n_controls\n",
    "                          np.nan, #var_cases\n",
    "                          np.nan #var_controls\n",
    "                         ]\n",
    "            results_df = results_df.append(pd.Series(row_to_add, index=results_df.columns), ignore_index=True)\n",
    "            \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use our previously defined wrapper function to run the PheWAS 2 times:\n",
    "- Testing all harmonized variables against cholesterol in females in the FHS study\n",
    "- Testing all harmonized variables against cholesterol in males in the FHS study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhs_female_df = run_phewas(fhs_subset[fhs_subset[sex_path] == 'Female'],\n",
    "                                     \"categorical_cholesterol\", \n",
    "                                     continuous_varnames, \n",
    "                                     categorical_varnames, \n",
    "                                     case_value=1, \n",
    "                                     control_value=0)\n",
    "fhs_female_df['sex'] = 'Female'\n",
    "fhs_female_df['study'] = 'FHS'\n",
    "\n",
    "fhs_male_df = run_phewas(fhs_subset[fhs_subset[sex_path] == 'Male'],\n",
    "                                     \"categorical_cholesterol\", \n",
    "                                     continuous_varnames, \n",
    "                                     categorical_varnames, \n",
    "                                     case_value=1, \n",
    "                                     control_value=0)\n",
    "fhs_male_df['sex'] = 'Male'\n",
    "fhs_male_df['study'] = 'FHS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([fhs_female_df, fhs_male_df])\n",
    "combined_df = combined_df[combined_df.pval != 0] #Removing pvalues equal to 0\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are running many statistical tests, we need to perform a p-value adjustment. Here, we use the holm-bonferroni method with an alpha of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['adj_pvalues'] = smt.multipletests(combined_df['pval'], alpha=0.01, method='holm')[1]\n",
    "combined_df['log_adj_pvalues'] = -1*np.log10(combined_df['adj_pvalues'])\n",
    "adjusted_alpha = -1*np.log10(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualization of results in a Manhattan plot\n",
    "We plot a Manhattan plot, commonly used in PheWAS analyses, to visualize our results. First we will organize our data for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and record categories for each concept code\n",
    "def categorize_function(x):\n",
    "    return(x.split('\\\\')[2])\n",
    "\n",
    "combined_df['category'] = combined_df['concept_code'].apply(categorize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = combined_df.sort_values(['category'])\n",
    "plot_df.reset_index(inplace=True, drop=True)\n",
    "plot_df['i'] = plot_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x axis represents each of the phenotypes tested, and the y axis represents their associated -log10 p value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify top 5 adjusted p value results \n",
    "# FHS\n",
    "fhs_labels_df = plot_df[plot_df.study == 'FHS']\n",
    "fhs_labels_df = fhs_labels_df[fhs_labels_df.log_adj_pvalues >= fhs_labels_df.log_adj_pvalues.sort_values(na_position = 'first').iloc[-5]]\n",
    "fhs_labels_df['offset'] = [15, -15, -30, 0, -10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Manhattan plot for FHS:\n",
    "\n",
    "plot = sns.relplot(data=plot_df[plot_df.study == 'FHS'], \n",
    "                   x='i', y='log_adj_pvalues', aspect=3.7, style = 'sex',\n",
    "                   hue='category', palette = 'bright')\n",
    "groups=plot_df.groupby('category')['i'].median()\n",
    "plot.ax.set_xlabel('Phenotype Category')\n",
    "plot.ax.set_ylabel('-log10(p-value)')\n",
    "plot.ax.set_xticks(groups)\n",
    "#plot.ax.set_xticklabels(groups.index)\n",
    "plot.ax.set_xticklabels('')\n",
    "#plt.xticks(rotation = 10)\n",
    "# label points on the plot\n",
    "for x, y, z, offset in zip(fhs_labels_df['i'], fhs_labels_df['log_adj_pvalues'], fhs_labels_df['simplified_varname'], fhs_labels_df['offset']):\n",
    "    plt.text(x = x - 40, # x-coordinate position of data label\n",
    "             y = y + offset, # y-coordinate position of data label\n",
    "             s = textwrap.fill(z, width=40, fix_sentence_endings=True, break_long_words=False)) #option for text wrapping, import textwrap\n",
    "plt.axhline(y=adjusted_alpha, color='r', linestyle = 'dotted')\n",
    "plot.fig.suptitle('Association between phenotypic variables and cholesterol level status within the Framingham Heart Study (FHS) cohort');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View top 5 p-values for each study/sex combination\n",
    "fhs_df = plot_df[plot_df.study == \"FHS\"]\n",
    "print(\"FHS Females:\")\n",
    "fhs_females_df = fhs_df[fhs_df.sex == \"Female\"]\n",
    "fhs_females_df = fhs_females_df[fhs_females_df.log_adj_pvalues >= fhs_females_df.log_adj_pvalues.sort_values(na_position = 'first').iloc[-5]]\n",
    "print(fhs_females_df[['simplified_varname', 'pval', 'sex', 'study']])\n",
    "\n",
    "print(\"FHS Males:\")\n",
    "fhs_males_df = fhs_df[fhs_df.sex == \"Male\"]\n",
    "fhs_males_df = fhs_males_df[fhs_males_df.log_adj_pvalues >= fhs_males_df.log_adj_pvalues.sort_values(na_position = 'first').iloc[-5]]\n",
    "print(fhs_males_df[['simplified_varname', 'pval', 'sex', 'study']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
