{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIC-SURE python API use-case: Phenome-Wide analysis on *NHLBI BioData CatalystÂ® (BDC)* studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an illustration example about how to query data using the python **PIC-SURE API**. It takes as use-case a simple PheWAS analysis. This notebook is intentionally straightforward, and explanation provided are only aimed at guiding through the PheWAS analysis process. For a more step-by-step introduction to the python PIC-SURE API, see the `1_PICSURE_API_101.ipynb` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure to review the \"Get your security token\" documentation, which exists in the [`README.md` file](../README.md). It explains how to get a security token, which is mandatory to use the PIC-SURE API.**\n",
    "\n",
    "To set up your token file, be sure to run the [`Workspace_setup.ipynb` file](./Workspace_setup.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System requirements\n",
    "- Python 3.6 or later\n",
    "- pip python package manager, already available in most systems with a python interpreter installed\n",
    "\n",
    "**Note that if you are using the dedicated PIC-SURE environment within the *BDC Powered by Seven Bridges* platform, the necessary packages have already been installed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# BDC Powered by Terra users uncomment the following line to specify package install location\n",
    "# sys.path.insert(0, r\"/home/jupyter/.local/lib/python3.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PicSureClient\n",
    "import PicSureBdcAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Pandas DataFrame display options\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "\n",
    "# Matplotlib display parameters\n",
    "plt.rcParams[\"figure.figsize\"] = (14,8)\n",
    "font = {'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to a PIC-SURE network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "token_file = \"token.txt\"\n",
    "\n",
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()\n",
    "    \n",
    "bdc = PicSureBdcAdapter.Adapter(PICSURE_network_URL, my_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PheWAS analysis\n",
    "*Note: This example is not meant to be publication-ready, but rather serve as a guide or starting point to perform PheWAS.*\n",
    "\n",
    "This PheWAS analysis focuses on the TOPMed DCC Harmonized Variables. \n",
    "We leverage the harmonized variables to provide an example PheWAS focused on total cholesterol in FHS.\n",
    "The PIC-SURE API is helpful in wrangling our phenotypic data. \n",
    "\n",
    "In a nutshell, this PheWAS analysis follows the subsequent steps:\n",
    "1. Retrieving the variable dictionary, using the PIC-SURE API dedicated methods\n",
    "2. Using the PIC-SURE API to select variables and retrieve data\n",
    "3. Data management\n",
    "4. Statistical analysis for each study and sex\n",
    "5. Visualization of results in Manhattan Plot\n",
    "\n",
    "With this, we are tackling two different analysis considerations of a PheWAS: \n",
    "1. Using multiple variables in a PheWAS. In this example, we are looking into sex differences of total \n",
    "2. Harmonization and meta-analysis issues when using data from multiple studies or datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Retrieving variable dictionary from PIC-SURE\n",
    "The first step to conducting the PheWAS is to retrieve information about the variables that will be used in the analysis. For this example, we will be using variables from the TOPMed Data Coordinating Center (DCC) Harmonized data set. \n",
    "\n",
    "The Data Harmonization effort aims to produce \"a high quality, lasting resource of publicly available and thoroughly documented harmonized phenotype variables\". The TOPMed DCC collaborates with Working Group members and phenotype experts on this endeavour. So far, 44 harmonized variables are accessible through PIC-SURE API (in addition to the age at which each variable value has been collected for a given subject).\n",
    "\n",
    "Which phenotypic characteristics are included in the harmonized variables?\n",
    "\n",
    "- Key NHLBI phenotypes\n",
    "    - Blood cell counts\n",
    "    - VTE\n",
    "    - Atherosclerosis-related phenotypes\n",
    "    - Lipids\n",
    "    - Blood pressure\n",
    "    \n",
    "    \n",
    "- Common covariates\n",
    "    - Height\n",
    "    - Weight\n",
    "    - BMI\n",
    "    - Smoking status\n",
    "    - Race/ethnicity\n",
    "\n",
    "More information about the variable harmonization process is available at https://www.nhlbiwgs.org/sites/default/files/pheno_harmonization_guidelines.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we find all 44 DCC harmonized variables. For more details on this process, see the `2_TOPMed_DCC_Harmonized_Variables_analysis` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "harmonized_dictionary = bdc.useDictionary().dictionary().find('harmonized')\n",
    "harmonized_dataframe = harmonized_dictionary.dataframe()\n",
    "vars_to_remove = harmonized_dataframe.columnmeta_name.str.contains(\"age at measurement|harmonization unit\")\n",
    "harmonized_dataframe = harmonized_dataframe[-vars_to_remove]\n",
    "harmonized_dataframe = harmonized_dataframe[harmonized_dataframe['studyId'] == \"DCC Harmonized data set\"]\n",
    "\n",
    "print(harmonized_dataframe.shape)\n",
    "harmonized_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using the PIC-SURE API to select variables and retrieve data\n",
    "Now that we've retrieved the variable information, we need to select our variable of interest. In this example, we are interested in exploring the relationship between the harmonized variables and blood cholesterol. Specifically, we will find the HPDS path that contains \"Blood mass concentration of total cholesterol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the dependent variable - total cholesterol\n",
    "cholesterol_variables = harmonized_dataframe[harmonized_dataframe.columnmeta_HPDS_PATH.str.contains('cholesterol')]\n",
    "\n",
    "cholesterol_path = list(cholesterol_variables.columnmeta_HPDS_PATH)[0]\n",
    "cholesterol_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create full list of concept paths with cholesterol_path removed\n",
    "selected_vars = list(harmonized_dataframe.columnmeta_HPDS_PATH)\n",
    "selected_vars.remove(cholesterol_path)\n",
    "selected_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to create our query and retrieve the dataframe. This query will consist of two parts:\n",
    "1. **Any record of `cholesterol_path`.** By performing an \"any record of\" filter on the `cholesterol_path`, we will filter out all participants that do not have total blood cholesterol measurements. This allows us to perform more meaningful statistical analysis on the data.\n",
    "2. **Select all remaining harmonized variables (`selected_vars`).** We will then add all of the remaining harmonized variables to the query, which will allow us to retrieve this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a query\n",
    "authPicSure = bdc.useAuthPicSure()\n",
    "myquery = authPicSure.query()\n",
    "myquery.anyof().add(cholesterol_path)\n",
    "myquery.select().add(selected_vars)\n",
    "facts = myquery.getResultsDataFrame(low_memory = False)\n",
    "facts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data-management\n",
    "Now that we have retrieved the data, we shall perform some data management steps to prepare for the statistical analysis. First, we will identify which variables are categorical and which are continuous using the `columnmeta_data_type` column of the harmonized dictionary. This is an example of how the PIC-SURE API greatly simplifies this step for the user, as categorizing variables can be tricky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categorical_dataframe = harmonized_dataframe[harmonized_dataframe.columnmeta_data_type == \"Categorical\"]\n",
    "categorical_paths = list(categorical_dataframe.columnmeta_HPDS_PATH)\n",
    "\n",
    "continuous_dataframe = harmonized_dataframe[harmonized_dataframe.columnmeta_data_type == \"Continuous\"]\n",
    "continuous_paths = list(continuous_dataframe.columnmeta_HPDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove cholesterol_path from continuous_paths\n",
    "continuous_paths.remove(cholesterol_path) \n",
    "\n",
    "# remove subcohort concept path from categorical_paths\n",
    "categorical_paths.remove(\"\\\\DCC Harmonized data set\\\\demographic\\\\subcohort_1\\\\\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "To perform this PheWAS, we will frame two participant cohorts in the context of the dependent variable of interest. In this example, we are interested in blood cholesterol. However, `Blood mass concentation of total cholesterol` is a continuous variable. We shall convert this variable into a binary variable with two groups, Normal/Low and High cholesterol levels, by applying a [threshold of 200mg/dL](https://www.mayoclinic.org/diseases-conditions/high-blood-cholesterol/diagnosis-treatment/drc-20350806). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    list(facts[cholesterol_path] <= 200),\n",
    "    list(facts[cholesterol_path] > 200)\n",
    "]\n",
    "outputs = [0, 1] \n",
    "# Note: 0 indicates Normal/Low blood pressure, while 1 indicates High blood pressue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.select(conditions, outputs)\n",
    "facts['categorical_cholesterol'] = pd.Series(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also specify the variable name for the covariate we are interested in, in this case Sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_path = list(facts.filter(regex = 'sex'))[0]\n",
    "sex_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also select our cohorts of interest. In this example, we are interested in participants from the Framingham Heart Study (FHS. We can utilize the `\\\\DCC Harmonized data set\\\\demographic\\\\subcohort_1\\\\` concept path in the DCC Harmonized data set to select the participants of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhs_subset = facts[facts['\\\\DCC Harmonized data set\\\\demographic\\\\subcohort_1\\\\'].str.contains('FHS') == True]\n",
    "\n",
    "print(fhs_subset['\\\\DCC Harmonized data set\\\\demographic\\\\subcohort_1\\\\'].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to handle any columns that have multiple values per participant. In PIC-SURE data, multiple values are recorded using a tab, `\\t`, as the delimiter. The functions below handle these by returning the mean of numeric values and the unique strings of categorical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mixed_cell(cell):\n",
    "    # Split by tab\n",
    "    items = str(cell).split('\\t')\n",
    "    # Try to convert all to float\n",
    "    try:\n",
    "        nums = [float(x) for x in items]\n",
    "        return np.mean(nums)\n",
    "    except ValueError:\n",
    "        # Not all are numbers, treat as categorical\n",
    "        first = items[0]\n",
    "        if all(x == first for x in items):\n",
    "            return first\n",
    "        else:\n",
    "            return f\"{items}\"\n",
    "\n",
    "def process_tab_separated_columns(df, cols=None):\n",
    "    df_processed = df.copy()\n",
    "    if cols is None:\n",
    "        # Try to infer columns with tabs (optional)\n",
    "        cols = [col for col in df.columns if df[col].astype(str).str.contains('\\t').any()]\n",
    "    for col in cols:\n",
    "        df_processed[col] = df_processed[col].apply(process_mixed_cell)\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhs_subset = process_tab_separated_columns(fhs_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Statistical analysis\n",
    "Two different association tests will be carried out according to variables data types:\n",
    "- Logistic regression for continuous variables, using the `Logit` statsmodels function\n",
    "- Fisher exact test for categorical variables, using the `chi2_contingency` scipy.stats function\n",
    "\n",
    "We will create two functions, `test_continuous` and `test_categorical`, to perform these statistical tests. \n",
    "An additional function, `check_vars`, will be used to check if the data passes some assumptions of these tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.discrete.discrete_model as sm\n",
    "import statistics\n",
    "from scipy.stats import chi2_contingency\n",
    "import statsmodels.stats.multitest as smt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_continuous(dependent_vec, independent_vec):\n",
    "    model = sm.Logit(dependent_vec, independent_vec, missing='drop')\n",
    "    pval = model.fit().pvalues[0]\n",
    "    return(pval)\n",
    "\n",
    "def test_categorical(dependent_vec, independent_vec):\n",
    "    contingency_table = pd.crosstab(index=dependent_vec, columns=independent_vec)\n",
    "    pval = chi2_contingency(contingency_table)[1]\n",
    "    return pval\n",
    "\n",
    "def check_vars(dependent_var, other_var, df, case_value, control_value):\n",
    "    check_pass = False\n",
    "    concept_vec = df.iloc[:,1].value_counts()\n",
    "    if len(concept_vec) > 1:\n",
    "        check_pass = True\n",
    "    return check_pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the previously created functions into one broad analysis function: ```run_phewas```. This would allow the user to run a variation of the analyses described here simply by modifying the calls to the function. The arguments are described below.\n",
    "- `facts`: a dataframe representing the results from your PIC-SURE query. This dataframe can be filtered as needed.\n",
    "- `dependent_var`: the column name corresponding to the name of your outcome varible. In this example. 'categorical_cholesterol'.\n",
    "- `continuous_varnames`: a vector containing all column names of continuous variables within the facts dataframe which you would like to test.\n",
    "- `categorical_varnames`: a vector containing all column names of categorical variables within the facts dataframe which you would like to test.\n",
    "- `case_value`: the value corresponding to the 'cases' in the dependent_var vector\n",
    "- `control_value`: the value corresponding to the 'controls' in the dependent_var vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_phewas(facts, dependent_var, continuous_varnames, categorical_varnames, case_value, control_value):\n",
    "    results_df = pd.DataFrame(columns=['concept_code', \n",
    "                                       'simplified_varname', \n",
    "                                       'vartype',\n",
    "                                       'pval',\n",
    "                                       'n_cases',\n",
    "                                       'n_controls',\n",
    "                                       'var_cases',\n",
    "                                       'var_controls'\n",
    "                                      ])\n",
    "    \n",
    "    for other_var in continuous_varnames:\n",
    "        df = facts[[dependent_var, other_var]]\n",
    "        check_pass = check_vars(dependent_var, other_var, df, case_value, control_value)\n",
    "        if check_pass:\n",
    "            cases = df[df.iloc[:,0]==case_value]\n",
    "            controls = df[df.iloc[:,0]==control_value]\n",
    "            row_to_add = [other_var, # concept_code\n",
    "                          other_var.split('\\\\')[-2], #simplified_varname\n",
    "                          'continuous', #vartype\n",
    "                          test_continuous(df.iloc[:,0], df.iloc[:,1]), #pval\n",
    "                          len(cases), #n_cases\n",
    "                          len(controls), #n_controls\n",
    "                          statistics.variance(cases.iloc[:,1].dropna()), #var_cases\n",
    "                          statistics.variance(controls.iloc[:,1].dropna()) #var_controls\n",
    "                         ]\n",
    "            results_df = pd.concat([results_df, pd.DataFrame(data=[row_to_add], columns=results_df.columns)], ignore_index=True)\n",
    "            \n",
    "    for other_var in categorical_varnames:\n",
    "        df = facts[[dependent_var, other_var]]\n",
    "        check_pass = check_vars(dependent_var, other_var, df, case_value, control_value)\n",
    "        if check_pass:\n",
    "            row_to_add = [other_var, #concept_code\n",
    "                          other_var.split('\\\\')[-2], #simplified_varname\n",
    "                          'categorical', #vartype\n",
    "                          test_categorical(df.iloc[:,0], df.iloc[:,1]), #pval\n",
    "                          len(df[df.iloc[:,0]==case_value]), #n_cases\n",
    "                          len(df[df.iloc[:,0]==control_value]), #n_controls\n",
    "                          np.nan, #var_cases\n",
    "                          np.nan #var_controls\n",
    "                         ]\n",
    "            results_df = pd.concat([results_df, pd.DataFrame(data=[row_to_add], columns=results_df.columns)], ignore_index=True)\n",
    "            \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use our previously defined wrapper function to run the PheWAS 2 times:\n",
    "- Testing all harmonized variables against cholesterol in females in the FHS study\n",
    "- Testing all harmonized variables against cholesterol in males in the FHS study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fhs_female_df = run_phewas(fhs_subset[fhs_subset[sex_path] == 'Female'],\n",
    "                                     \"categorical_cholesterol\", \n",
    "                                     continuous_paths, \n",
    "                                     categorical_paths, \n",
    "                                     case_value=1, \n",
    "                                     control_value=0)\n",
    "fhs_female_df['sex'] = 'Female'\n",
    "fhs_female_df['study'] = 'FHS'\n",
    "\n",
    "fhs_male_df = run_phewas(fhs_subset[fhs_subset[sex_path] == 'Male'],\n",
    "                                     \"categorical_cholesterol\", \n",
    "                                     continuous_paths, \n",
    "                                     categorical_paths, \n",
    "                                     case_value=1, \n",
    "                                     control_value=0)\n",
    "fhs_male_df['sex'] = 'Male'\n",
    "fhs_male_df['study'] = 'FHS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([fhs_female_df, fhs_male_df])\n",
    "combined_df = combined_df[combined_df.pval != 0] #Removing pvalues equal to 0\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are running many statistical tests, we need to perform a p-value adjustment. Here, we use the holm-bonferroni method with an alpha of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['adj_pvalues'] = smt.multipletests(combined_df['pval'], alpha=0.01, method='holm')[1]\n",
    "combined_df['log_adj_pvalues'] = -1*np.log10(combined_df['adj_pvalues'])\n",
    "adjusted_alpha = -1*np.log10(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualization of results in a Manhattan plot\n",
    "We plot a Manhattan plot, commonly used in PheWAS analyses, to visualize our results. First we will organize our data for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and record categories for each concept code\n",
    "def categorize_function(x):\n",
    "    return(x.split('\\\\')[2])\n",
    "\n",
    "combined_df['category'] = combined_df['concept_code'].apply(categorize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = combined_df.sort_values(['category'])\n",
    "plot_df.reset_index(inplace=True, drop=True)\n",
    "plot_df['i'] = plot_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x axis represents each of the phenotypes tested, and the y axis represents their associated -log10 p value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify top 5 adjusted p value results for each study\n",
    "# FHS\n",
    "fhs_labels_df = plot_df[plot_df.study == 'FHS']\n",
    "fhs_labels_df = fhs_labels_df[fhs_labels_df.log_adj_pvalues >= fhs_labels_df.log_adj_pvalues.sort_values(na_position = 'first').iloc[-5]]\n",
    "fhs_labels_df['offset'] = [15, -15, -30, 0, -10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Manhattan plot for FHS:\n",
    "\n",
    "plot = sns.relplot(data=plot_df[plot_df.study == 'FHS'], \n",
    "                   x='i', y='log_adj_pvalues', aspect=3.7, style = 'sex',\n",
    "                   hue='category', palette = 'bright')\n",
    "groups=plot_df.groupby('category')['i'].median()\n",
    "plot.ax.set_xlabel('Phenotype Category')\n",
    "plot.ax.set_ylabel('-log10(p-value)')\n",
    "plot.ax.set_xticks(groups)\n",
    "#plot.ax.set_xticklabels(groups.index)\n",
    "plot.ax.set_xticklabels('')\n",
    "#plt.xticks(rotation = 10)\n",
    "# label points on the plot\n",
    "for x, y, z, offset in zip(fhs_labels_df['i'], fhs_labels_df['log_adj_pvalues'], fhs_labels_df['simplified_varname'], fhs_labels_df['offset']):\n",
    "    plt.text(x = x, # x-coordinate position of data label\n",
    "             y = y, # y-coordinate position of data label\n",
    "             s = textwrap.fill(z, width=40, fix_sentence_endings=True, break_long_words=False)) #option for text wrapping, import textwrap\n",
    "plt.axhline(y=adjusted_alpha, color='r', linestyle = 'dotted')\n",
    "plot.fig.suptitle('Association between phenotypic variables and cholesterol level status within the Framingham Heart Study (FHS) cohort');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View top 5 p-values for each study/sex combination\n",
    "fhs_df = plot_df[plot_df.study == \"FHS\"]\n",
    "print(\"FHS Females:\")\n",
    "fhs_females_df = fhs_df[fhs_df.sex == \"Female\"]\n",
    "logpthresh = fhs_females_df.log_adj_pvalues.sort_values(na_position = 'first').iloc[-5]\n",
    "fhs_females_df = fhs_females_df[fhs_females_df.log_adj_pvalues >= logpthresh]\n",
    "print(fhs_females_df[['simplified_varname', 'pval', 'sex', 'study']])\n",
    "\n",
    "print(\"FHS Males:\")\n",
    "fhs_males_df = fhs_df[fhs_df.sex == \"Male\"]\n",
    "logpthresh = fhs_males_df.log_adj_pvalues.sort_values(na_position = 'first').iloc[-5]\n",
    "fhs_males_df = fhs_males_df[fhs_males_df.log_adj_pvalues >= logpthresh]\n",
    "print(fhs_males_df[['simplified_varname', 'pval', 'sex', 'study']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
