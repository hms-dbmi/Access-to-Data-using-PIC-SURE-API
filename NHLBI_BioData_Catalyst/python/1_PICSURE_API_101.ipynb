{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdccad7f",
   "metadata": {},
   "source": [
    "# Introduction to the PIC-SURE API\n",
    "This is a tutorial notebook aimed to get the user quickly up and running with the PIC-SURE API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adb6d3",
   "metadata": {},
   "source": [
    "## PIC-SURE python API\n",
    "### What is PIC-SURE?\n",
    "As part of the *NHLBI BioData CatalystÂ® (BDC)* ecosystem, the Patient Information Commons: Standard Unification of Research Elements (PIC-SURE) platform has been integrating clinical and genomic datasets from multiple TOPMed and TOPMed-related studies funded by the National Heart, Lung, and Blood Institute (NHLBI). \n",
    "\n",
    "Original data exposed through the PIC-SURE API encompasses a large heterogeneity of data organization underneath. PIC-SURE hides this complexity and esposes the different study datasets in a single tabular format. By simplifying the process of data extraction, it allows investigators to focus on downstream analysis and to facilitate reproducible science. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb382d6",
   "metadata": {},
   "source": [
    "### More about PIC-SURE\n",
    "The API is available in two different programming languages, python and R, enabling investigators to query the database the same way using either language.\n",
    "\n",
    "PIC-SURE is a larger project from which the R and python PIC-SURE APIs are only a small part. Among other things, PIC-SURE also offers a graphical user interface that allows researchers to explore variables across multiple studies, filter participants that match criteria, and create cohorts from this interactive exploration.\n",
    "\n",
    "The python API is actively developed by the Avillach Lab at Harvard Medical School. \n",
    "\n",
    "PIC-SURE API GitHub repositories:\n",
    "* https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds\n",
    "* https://github.com/hms-dbmi/pic-sure-python-adapter-hpds\n",
    "* https://github.com/hms-dbmi/pic-sure-python-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c4076",
   "metadata": {},
   "source": [
    " ------- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899f19e",
   "metadata": {},
   "source": [
    "## Getting your user-specific security token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33abee4",
   "metadata": {},
   "source": [
    "**Before running this notebook, please be sure to review the \"Get your security token\" documentation, which exists in the [`README.md` file](../README.md). It explains how to get a security token, which is mandatory to use the PIC-SURE API.**\n",
    "\n",
    "To set up your token file, be sure to run the [`Workspace_setup.ipynb` file](./Workspace_setup.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bdf24",
   "metadata": {},
   "source": [
    "## Environment set-up\n",
    "\n",
    "### Pre-requisites\n",
    "* python 3.6 or later\n",
    "* pip python package manager, already available in most systems with a python interpreter installed (link to pip)\n",
    "\n",
    "### Install packages\n",
    "The first step to using the PIC-SURE API is to install the packages needed. The following code installs the PIC-SURE API components from GitHub, specifically:\n",
    "* PIC-SURE Client\n",
    "* PIC-SURE Adapter\n",
    "* *BDC-PIC-SURE* Adapter\n",
    "\n",
    "**Note that if you are using the dedicated PIC-SURE environment within the *BDC Powered by Seven Bridges* platform, the necessary packages have already been installed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca336d1-feb8-408c-b3fa-8ab17015d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# BDC Powered by Terra users uncomment the following line to specify package install location\n",
    "# sys.path.insert(0, r\"/home/jupyter/.local/lib/python3.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a0f225-1b8f-4580-ba0d-be33390b2943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
      "  Cloning https://github.com/hms-dbmi/pic-sure-python-client.git to /tmp/pip-req-build-rbq_optp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/hms-dbmi/pic-sure-python-client.git /tmp/pip-req-build-rbq_optp\n",
      "  Resolved https://github.com/hms-dbmi/pic-sure-python-client.git to commit 8cd1d3d89e8539baf972dee96dc00d88e4853004\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: PicSureClient\n",
      "  Building wheel for PicSureClient (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PicSureClient: filename=PicSureClient-0.1.0-py2.py3-none-any.whl size=10726 sha256=388eaa08f346c4c347dee78cdfd1ffe056934fe8116e07040ac18e1a15beb442\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-eo1prcmq/wheels/90/65/c4/e74447484bdae71b64f3f0a500bc7b3d9d6ee7edc62ade6667\n",
      "Successfully built PicSureClient\n",
      "Installing collected packages: PicSureClient\n",
      "  Attempting uninstall: PicSureClient\n",
      "    Found existing installation: PicSureClient 0.1.0\n",
      "    Uninstalling PicSureClient-0.1.0:\n",
      "      Successfully uninstalled PicSureClient-0.1.0\n",
      "Successfully installed PicSureClient-0.1.0\n",
      "Collecting git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
      "  Cloning https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git to /tmp/pip-req-build-uwyz74li\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git /tmp/pip-req-build-uwyz74li\n",
      "  Resolved https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git to commit 696907e7ea18e2d3b511b50a355df27ea869d4a7\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httplib2\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Building wheels for collected packages: PicSureHpdsLib\n",
      "  Building wheel for PicSureHpdsLib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PicSureHpdsLib: filename=PicSureHpdsLib-0.9.0-py2.py3-none-any.whl size=22162 sha256=98abf248c5c68d8d19290dacc37f36f927e37d700121886116af58a1c69e2262\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-utc7ep9w/wheels/75/32/ca/ca45a25b13de6d9ec7a4d584241d588f730f81fadf580ff34d\n",
      "Successfully built PicSureHpdsLib\n",
      "Installing collected packages: pyparsing, httplib2, PicSureHpdsLib\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.0\n",
      "    Uninstalling pyparsing-3.2.0:\n",
      "      Successfully uninstalled pyparsing-3.2.0\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.22.0\n",
      "    Uninstalling httplib2-0.22.0:\n",
      "      Successfully uninstalled httplib2-0.22.0\n",
      "  Attempting uninstall: PicSureHpdsLib\n",
      "    Found existing installation: PicSureHpdsLib 0.9.0\n",
      "    Uninstalling PicSureHpdsLib-0.9.0:\n",
      "      Successfully uninstalled PicSureHpdsLib-0.9.0\n",
      "Successfully installed PicSureHpdsLib-0.9.0 httplib2-0.22.0 pyparsing-3.2.0\n",
      "Collecting git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git\n",
      "  Cloning https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git to /tmp/pip-req-build-x7kii0vs\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git /tmp/pip-req-build-x7kii0vs\n",
      "  Resolved https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git to commit f696156b2e798606920303decb8fcf894231efd3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httplib2\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Building wheels for collected packages: PicSureBdcAdapter\n",
      "  Building wheel for PicSureBdcAdapter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PicSureBdcAdapter: filename=PicSureBdcAdapter-1.0.0-py3-none-any.whl size=12830 sha256=497506943e4103065625a3032e5799eb0778823b4c101398dd4904025d01743f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sie41yim/wheels/e4/3c/b0/64cb444206d84ce321e561c3fdd04f9803f4798c9d759f48e7\n",
      "Successfully built PicSureBdcAdapter\n",
      "Installing collected packages: pyparsing, httplib2, PicSureBdcAdapter\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.0\n",
      "    Uninstalling pyparsing-3.2.0:\n",
      "      Successfully uninstalled pyparsing-3.2.0\n",
      "  Attempting uninstall: httplib2\n",
      "    Found existing installation: httplib2 0.22.0\n",
      "    Uninstalling httplib2-0.22.0:\n",
      "      Successfully uninstalled httplib2-0.22.0\n",
      "  Attempting uninstall: PicSureBdcAdapter\n",
      "    Found existing installation: PicSureBdcAdapter 1.0.0\n",
      "    Uninstalling PicSureBdcAdapter-1.0.0:\n",
      "      Successfully uninstalled PicSureBdcAdapter-1.0.0\n",
      "Successfully installed PicSureBdcAdapter-1.0.0 httplib2-0.22.0 pyparsing-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-client.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-python-adapter-hpds.git\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall git+https://github.com/hms-dbmi/pic-sure-biodatacatalyst-python-adapter-hpds.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d21f184-0ba1-49bd-84ad-82cc129ee1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PicSureClient\n",
    "import PicSureBdcAdapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a81da8",
   "metadata": {},
   "source": [
    "## Connecting to a PIC-SURE resource\n",
    "\n",
    "The following is required to get access to the PIC-SURE API:\n",
    "* a network URL\n",
    "* a user-specific security token\n",
    "\n",
    "The following code specifies the network URL as the *BDC Powered by PIC-SURE* URL and references the user-specific token saved as `token.txt`.\n",
    "\n",
    "If you have not already retrieved your user-specific token, please refer to the \"Get your security token\" section of the `README.md` file and the `Workspace_setup.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5e78a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+------------------------------------------------------+\n",
      "|  Resource UUID                       |  Resource Name                                       |\n",
      "+--------------------------------------+------------------------------------------------------+\n",
      "| ca0ad4a9-130a-3a8a-ae00-e35b07f1108b | visualization                                        |\n",
      "| 02e23f52-f354-4e8b-992c-d37c8b9ba140 | auth-hpds                                            |\n",
      "| 36363664-6231-6134-2d38-6538652d3131 | dictionary                                           |\n",
      "+--------------------------------------+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "PICSURE_network_URL = \"https://picsure.biodatacatalyst.nhlbi.nih.gov/picsure\"\n",
    "token_file = \"token.txt\"\n",
    "\n",
    "with open(token_file, \"r\") as f:\n",
    "    my_token = f.read()\n",
    "    \n",
    "bdc = PicSureBdcAdapter.Adapter(PICSURE_network_URL, my_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a290ae",
   "metadata": {},
   "source": [
    "## Getting help with the PIC-SURE API\n",
    "Each of the objects in the PIC-SURE API have a `help()` method that you can use to get more information about its functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39d3179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        [HELP] PicSureHpdsLib.Adapter(picsure_connection)\n",
      "            .version()                      gives version information for library\n",
      "            .list()                         lists available resources\n",
      "            .useResource(resource_uuid)     returns an object for selected resource\n",
      "            .unlockResource(resource_uuid, key)     For Administrators Use\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "bdc.help()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f9b15",
   "metadata": {},
   "source": [
    "For example, the above output lists and briefly defines the four methods that can be used with the `bdc` resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aecd1cf",
   "metadata": {},
   "source": [
    "## Using the PIC-SURE variables dictionary\n",
    "Now that you have set up your connection to the PIC-SURE API, let's determine which study or studies you are authorized to access. The `dictionary` method can be used to search the data dictionary for a specific term or to retrieve information about all the variables you are authorized to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "854f8390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = bdc.useDictionary().dictionary() # Set up the dictionary\n",
    "all_variables = dictionary.find() # Retrieve all variables you have access to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af702729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are authorized to access the following studies:\n",
      " {'phs001467', 'phs001032', 'phs001606', 'phs003533', 'phs003542', 'phs003017', 'phs000253', 'phs003562', 'phs001514', 'phs001544', 'phs002919', 'phs001359', 'phs002911', 'phs000921', 'phs001728', 'phs000820', 'phs001600', 'phs000553', 'phs000993', 'phs002299', 'phs003654', 'phs000964', 'phs001024', 'phs000479', 'phs000703', 'phs001189', 'phs000007', 'phs001293', 'phs002808', 'phs001814', 'phs000587', 'phs001402', 'phs002910', 'phs000810', 'phs001608', 'phs002385', 'phs001605', 'phs000166', 'phs001679', 'phs000997', 'phs001252', 'phs002694', 'phs001143', 'phs001727', 'phs003543', 'phs001062', 'phs001074', 'phs000920', 'phs001434', 'phs002913', 'phs003593', 'phs001341', 'phs001215', 'phs002752', 'phs003231', 'phs001603', 'phs001412', 'tutorial-biolincc_camp', 'phs000974', 'phs001927', 'phs000571', 'phs001237', 'phs001607', 'phs000954', 'phs001725', 'phs001599', 'phs001546', 'phs000972', 'phs001602', 'phs003637', 'tutorial-biolincc_digitalis', 'phs001395', 'phs002710', 'phs000951', 'phs001001', 'phs002715', 'phs000956', 'phs003578', 'phs001592', 'phs003551', 'phs002348', 'phs001539', 'phs001543', 'phs001012', 'phs001218', 'phs001472', 'phs000784', 'phs001238', 'phs001892', 'phs001735', 'phs001601', 'phs001416', 'open_access-1000Genomes', 'phs001933', 'phs001729', 'phs002383', 'phs002386', 'phs000287', 'phs000209', 'phs000179', 'phs001387', 'phs001446', 'phs001013', 'phs001624', 'phs003470', 'phs000914', 'phs001542', 'phs003463', 'phs001194', 'phs003529', 'phs002415', 'phs003524', 'phs003639', 'phs002988', 'phs003621', 'phs001604', 'phs002363', 'phs001217', 'phs002909', 'phs001368', 'phs001040', 'phs003708', 'phs001661', 'phs001644', 'phs001682', 'phs003212', 'phs001466', 'phs001180', 'phs003557', 'DCC Harmonized data set', 'phs001662', 'phs000200', 'phs001211', 'phs000422', 'tutorial-biolincc_framingham', 'phs001961', 'phs001545', 'phs002975', 'phs003063', 'phs001345', 'phs001732', 'phs001730', 'phs001547', 'phs002980', 'phs000284', 'phs003419', 'phs002908', 'phs000946', 'phs002362', 'phs001759', 'phs003028', 'phs000988', 'phs003461', 'phs001435', 'phs001515', 'phs001726', 'phs001598', 'phs001468', 'phs003566', 'phs001207'}\n"
     ]
    }
   ],
   "source": [
    "list_all_variables = all_variables.listPaths()\n",
    "studies = set([i.split(\"\\\\\")[1] for i in list_all_variables])\n",
    "print(\"You are authorized to access the following studies:\\n\", studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f0933-0a20-4fd0-a874-c5c85b34ac7f",
   "metadata": {},
   "source": [
    "For the rest of this example notebook, we will use one of the publicly available datasets available on PIC-SURE. This dataset is the \"Framingham Heart Study: Dataset for Teaching Purposes\", which is listed as `tutorial-biolincc_framingham` in the PIC-SURE output above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "310c55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phs_number = \"tutorial-biolincc_framingham\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f31a8",
   "metadata": {},
   "source": [
    "Now, let's find all of the variables associated with that study. We can search for these using the `find()` method and searching the phs accession number; in this case `tutorial-biolincc_framingham`.\n",
    "Additionally, we can view a list of the variables returned from this search using the `listPaths()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdb38a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variables = dictionary.find(phs_number) # Search for the phs accession number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4219397f-2763-40f5-8e58-8f992bec7496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3529"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_variables.count() # How many variables did the search return?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7213de2",
   "metadata": {},
   "source": [
    "We can view these variables in a detailed dataframe format using the `dataframe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57b819ec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "      <th>studyId</th>\n",
       "      <th>dtId</th>\n",
       "      <th>varId</th>\n",
       "      <th>is_categorical</th>\n",
       "      <th>is_continuous</th>\n",
       "      <th>columnmeta_is_stigmatized</th>\n",
       "      <th>columnmeta_name</th>\n",
       "      <th>description</th>\n",
       "      <th>columnmeta_min</th>\n",
       "      <th>...</th>\n",
       "      <th>columnmeta_data_type</th>\n",
       "      <th>derived_var_id</th>\n",
       "      <th>columnmeta_study_id</th>\n",
       "      <th>is_stigmatized</th>\n",
       "      <th>derived_var_name</th>\n",
       "      <th>derived_study_abv_name</th>\n",
       "      <th>derived_study_description</th>\n",
       "      <th>columnmeta_var_group_id</th>\n",
       "      <th>derived_group_name</th>\n",
       "      <th>columnmeta_HPDS_PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>All Variables</td>\n",
       "      <td>educ</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>false</td>\n",
       "      <td>educ</td>\n",
       "      <td>educ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>continuous</td>\n",
       "      <td>educ</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>false</td>\n",
       "      <td>educ</td>\n",
       "      <td>biolincc_framingham</td>\n",
       "      <td></td>\n",
       "      <td>All Variables</td>\n",
       "      <td></td>\n",
       "      <td>\\tutorial-biolincc_framingham\\educ\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>All Variables</td>\n",
       "      <td>AGE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>false</td>\n",
       "      <td>AGE</td>\n",
       "      <td>Age at exam (years)</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>continuous</td>\n",
       "      <td>AGE</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>false</td>\n",
       "      <td>AGE</td>\n",
       "      <td>biolincc_framingham</td>\n",
       "      <td>Framingham Heart Study : Dataset for Teaching ...</td>\n",
       "      <td>All Variables</td>\n",
       "      <td></td>\n",
       "      <td>\\tutorial-biolincc_framingham\\AGE\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Event did not occur during followup, Event di...</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>All Variables</td>\n",
       "      <td>ANGINA</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>ANGINA</td>\n",
       "      <td>Angina Pectoris</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>ANGINA</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>false</td>\n",
       "      <td>ANGINA</td>\n",
       "      <td>biolincc_framingham</td>\n",
       "      <td>Framingham Heart Study : Dataset for Teaching ...</td>\n",
       "      <td>All Variables</td>\n",
       "      <td></td>\n",
       "      <td>\\tutorial-biolincc_framingham\\ANGINA\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Event did not occur during followup, Event di...</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>All Variables</td>\n",
       "      <td>ANYCHD</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>ANYCHD</td>\n",
       "      <td>Angina Pectoris, Myocardial infarction (Hospit...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>ANYCHD</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>false</td>\n",
       "      <td>ANYCHD</td>\n",
       "      <td>biolincc_framingham</td>\n",
       "      <td>Framingham Heart Study : Dataset for Teaching ...</td>\n",
       "      <td>All Variables</td>\n",
       "      <td></td>\n",
       "      <td>\\tutorial-biolincc_framingham\\ANYCHD\\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Event did not occur during followup, Event di...</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>All Variables</td>\n",
       "      <td>STROKE</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>false</td>\n",
       "      <td>STROKE</td>\n",
       "      <td>Atherothrombotic infarction, Cerebral Embolism...</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>categorical</td>\n",
       "      <td>STROKE</td>\n",
       "      <td>tutorial-biolincc_framingham</td>\n",
       "      <td>false</td>\n",
       "      <td>STROKE</td>\n",
       "      <td>biolincc_framingham</td>\n",
       "      <td>Framingham Heart Study : Dataset for Teaching ...</td>\n",
       "      <td>All Variables</td>\n",
       "      <td></td>\n",
       "      <td>\\tutorial-biolincc_framingham\\STROKE\\</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              values  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [Event did not occur during followup, Event di...   \n",
       "3  [Event did not occur during followup, Event di...   \n",
       "4  [Event did not occur during followup, Event di...   \n",
       "\n",
       "                        studyId           dtId   varId  is_categorical  \\\n",
       "0  tutorial-biolincc_framingham  All Variables    educ           False   \n",
       "1  tutorial-biolincc_framingham  All Variables     AGE           False   \n",
       "2  tutorial-biolincc_framingham  All Variables  ANGINA            True   \n",
       "3  tutorial-biolincc_framingham  All Variables  ANYCHD            True   \n",
       "4  tutorial-biolincc_framingham  All Variables  STROKE            True   \n",
       "\n",
       "   is_continuous columnmeta_is_stigmatized columnmeta_name  \\\n",
       "0           True                     false            educ   \n",
       "1           True                     false             AGE   \n",
       "2          False                     false          ANGINA   \n",
       "3          False                     false          ANYCHD   \n",
       "4          False                     false          STROKE   \n",
       "\n",
       "                                         description columnmeta_min  ...  \\\n",
       "0                                               educ            1.0  ...   \n",
       "1                                Age at exam (years)           32.0  ...   \n",
       "2                                    Angina Pectoris                 ...   \n",
       "3  Angina Pectoris, Myocardial infarction (Hospit...                 ...   \n",
       "4  Atherothrombotic infarction, Cerebral Embolism...                 ...   \n",
       "\n",
       "  columnmeta_data_type derived_var_id           columnmeta_study_id  \\\n",
       "0           continuous           educ  tutorial-biolincc_framingham   \n",
       "1           continuous            AGE  tutorial-biolincc_framingham   \n",
       "2          categorical         ANGINA  tutorial-biolincc_framingham   \n",
       "3          categorical         ANYCHD  tutorial-biolincc_framingham   \n",
       "4          categorical         STROKE  tutorial-biolincc_framingham   \n",
       "\n",
       "  is_stigmatized derived_var_name derived_study_abv_name  \\\n",
       "0          false             educ    biolincc_framingham   \n",
       "1          false              AGE    biolincc_framingham   \n",
       "2          false           ANGINA    biolincc_framingham   \n",
       "3          false           ANYCHD    biolincc_framingham   \n",
       "4          false           STROKE    biolincc_framingham   \n",
       "\n",
       "                           derived_study_description columnmeta_var_group_id  \\\n",
       "0                                                              All Variables   \n",
       "1  Framingham Heart Study : Dataset for Teaching ...           All Variables   \n",
       "2  Framingham Heart Study : Dataset for Teaching ...           All Variables   \n",
       "3  Framingham Heart Study : Dataset for Teaching ...           All Variables   \n",
       "4  Framingham Heart Study : Dataset for Teaching ...           All Variables   \n",
       "\n",
       "  derived_group_name                   columnmeta_HPDS_PATH  \n",
       "0                       \\tutorial-biolincc_framingham\\educ\\  \n",
       "1                        \\tutorial-biolincc_framingham\\AGE\\  \n",
       "2                     \\tutorial-biolincc_framingham\\ANGINA\\  \n",
       "3                     \\tutorial-biolincc_framingham\\ANYCHD\\  \n",
       "4                     \\tutorial-biolincc_framingham\\STROKE\\  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_variables_df = my_variables.dataframe() # Save the results as a dataframe\n",
    "my_variables_df.head(5) # View the first 5 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106f6c48",
   "metadata": {},
   "source": [
    "PIC-SURE integrates clinical and genomic datasets across *BDC*, including TOPMed and TOPMed-related studies, COVID-19 studies, and BioLINCC studies. Each variable is organized as a concept path that contains information about the study, variable group, and variable. Though the specifics of the concept paths are dependent on the type of study, the overall information included is the same. \n",
    "\n",
    "Data Organization in PIC-SURE\n",
    "---------------------------------------\n",
    "| Data organization | TOPMed & TOPMed-related studies | BioLINCC & COVID-19 studies (including public data) |\n",
    "|-------------------|---------------------------------|-----------------------------|\n",
    "| General organization | Data organized using the format implemented by the database of Genotypes and Phenotypes (dbGaP). Generally, a given study will have several tables, and those tables have several variables. | Data do not follow dbGaP format; there are no phv or pht accessions. Data are organized in groups of like variables, when available. For example, variables like Age, Gender, and Race could be part of the Demographics variable group. |\n",
    "| Concept path structure | \\phs\\pht\\phv\\variable name\\ | \\phs\\variable name |\n",
    "| Variable ID | phv corresponding to the variable accession number | Equivalent to variable name | \n",
    "| Variable name | Encoded variable name that was used by the original submitters of the data | Encoded variable name that was used by the original submitters of the data |\n",
    "| Variable description | Description of the variable | Description of the variable, as available |\n",
    "| Dataset ID | pht corresponding to the trait table accession number | Equivalent to Dataset name | \n",
    "| Dataset name | Name of the trait table | Name of a group of like variables, as available | \n",
    "| Dataset description | Description of the trait table | Description of a group of like variables, as available |\n",
    "| Study ID | phs corresponding to the study accession number | phs corresponding to the study accession number |\n",
    "| Study description | Description of the study from dbGaP | Description of the study from dbGaP |\n",
    "\n",
    "*Note: The concept paths in PIC-SURE is used for querying. This is called `HPDS_PATH` in the data ditcionary shown above.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf425c6",
   "metadata": {},
   "source": [
    "The `listPaths()` function can be helpful to retrieve the concept paths for specific variables, which are used for building cohorts and selecting participant-level data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82854570",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_variables.listPaths()[0:10] # What are the first ten concept paths in my search results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5067a",
   "metadata": {},
   "source": [
    "We can also view additional information for individual variables using the `varInfo()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8ef93",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_var = my_variables.listPaths()[0] # Save the concept path for the first variable\n",
    "my_variables.varInfo(first_var) # Show information for that first concept path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accf1dbf",
   "metadata": {},
   "source": [
    "Now you can try to search for a term on your own. Below is sample code on how to search for the term `sex`. To practice searching the data dictionary, you can change \"sex\" to a term you are interested in. You will see the results displayed in the convenient dataframe format using the `displayResults()` method. Note - the results displayed will show results from all studies you have access to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd6b2b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_search = dictionary.find(\"sex\") # Change sex to be your term of interest\n",
    "my_search.displayResults().head() # Show the first few variables that match my search result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295cfe9",
   "metadata": {},
   "source": [
    "## Using PIC-SURE to build a query and retrieve data\n",
    "You can also use the PIC-SURE API to build a query and retrieve data. With this functionality, you can filter based on specific variables, add others, and export the data as a dataframe into this notebook. \n",
    "\n",
    "The first step to this is setting up the query object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9c30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "authPicSure = bdc.useAuthPicSure()\n",
    "query_example = authPicSure.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9875bf",
   "metadata": {},
   "source": [
    "There are several methods that can be used to build a query, which are listed below.\n",
    "\n",
    "| Method | Arguments / Input | Output|\n",
    "|--------|-------------------|-------|\n",
    "| query.select.add() | variable names (string) or list of strings | all variables included in the list (no record subsetting)|\n",
    "| query.require.add() | variable names (string) or list of strings | all variables; only records that do not contain null values for input variables |\n",
    "| query.anyof.add() | variable names (string) or list of strings | all variables; only records that contain at least one non-null value for input variables |\n",
    "| query.filter.add() | variable name and additional filtering values | input variable; only records that match filter criteria |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8fe991",
   "metadata": {},
   "source": [
    "As an example query, let's use the Framingham tutorial dataset to investigate the prevalence of hypertension and distribution of age of current smokers with body mass index greater than 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that only Framingham tutorial variables are shown in the data dictionary, which can vary based on individual access\n",
    "tutorial_df = my_variables_df[my_variables_df.studyId == phs_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346482bc",
   "metadata": {},
   "source": [
    "### Build a query with a categorical variable - Current smoker\n",
    "Let's practice building a query by filtering on variables. Based on the search for the Framingham tutorial dataset variables, we can save the concept path of the \"Current cigarette smoking at exam\" variable, which is a categorical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fdef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_variable_path = tutorial_df.HPDS_PATH[tutorial_df.description == \"Current cigarette smoking at exam\"]\n",
    "smoke_variable_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9757b1",
   "metadata": {},
   "source": [
    "We can take a look at the options of values to filter by using the `values` column of the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe07be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_df[\"values\"][tutorial_df.description == \"Current cigarette smoking at exam\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407762d",
   "metadata": {},
   "source": [
    "Let's apply a filter on the \"Current cigarette smoking at exam\" variable to only select participants with \"Current smoker.\" Note that though we are only filtering by one value, you can filter by multiple values by passing a list into `filter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f89374",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_example.filter().add(smoke_variable_path, \"Current smoker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b335b50c",
   "metadata": {},
   "source": [
    "#### Build a query with a continuous variable - BMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d12288",
   "metadata": {},
   "source": [
    "Let's practice building a query by filtering on a continuous variable, in this case, BMI. We can find the BMI concept path using a similar approach as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c121b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_variable_path = tutorial_df.HPDS_PATH[tutorial_df.columnmeta_name == \"BMI\"]\n",
    "bmi_variable_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c9fd3a",
   "metadata": {},
   "source": [
    "We can look at the minimum and maximum values of the variable using the `min` and `max` columns of the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ceb1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_df[[\"min\", \"max\"]][tutorial_df.columnmeta_name == \"BMI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf9513",
   "metadata": {},
   "source": [
    "Let's apply a filter on the \"Body Mass Index, weight in kilograms/height meters squared\" variable to select only participants with values greater than 20. Note that while in this example only a `min` is specified, a `max` can also be defined for the filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b10d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_example.filter().add(bmi_variable_path, min=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3598d3",
   "metadata": {},
   "source": [
    "#### Adding variables to include in export - Age and Hypertension\n",
    "In addition to adding filters, specific variables can be included in the export for analysis. Let's do this for the \"Age at exam (years)\" and \"Hypertensive. Defined as the first exam treated for high blood pressure or second exam in which either Systolic is 6 140 mmHg or Diastolic 6 90mmHg\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_variable_path = tutorial_df.loc[tutorial_df.description == \"Age at exam (years)\", \"HPDS_PATH\"].item()\n",
    "hyperten_variable_path = tutorial_df.loc[tutorial_df.columnmeta_name == \"HYPERTEN\", \"HPDS_PATH\"].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361f50c",
   "metadata": {},
   "source": [
    "Let's add these variables to our query. To do this, we can either use `select()`, `require()`, or `anyof()`. \n",
    "\n",
    "`select()` will add these variables for all participants we have filtered thus far, regardless whether they have a value for the variables or not.\n",
    "\n",
    "`anyof()` will add these variables for all participants that have at least one non-null value for the variables added.\n",
    "\n",
    "`require()` will add these variables for all participants that have only non-null values for all variables added.\n",
    "\n",
    "\n",
    "For this, let's use `require()` to only select participants that have information for both of these variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_example.require().add([age_variable_path, hyperten_variable_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5143a2",
   "metadata": {},
   "source": [
    "#### Exporting participant-level data from the query\n",
    "The query has been constructed and can now be exported for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9766cf",
   "metadata": {},
   "source": [
    "In the data dictionary dataframe shown previously, each row represented a single concept path or variable. In the query dataframe, the concept paths are added as columns with each row representing a participant with data that matches your query. \n",
    "\n",
    "The dataframe above should contain some automatically exported concept paths, such as `patient_id`, `Parent Study Accession with Subject ID`, `Topmed Study Accession with Subject ID`, and `consents`, and the concept paths we added to our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_results = query_example.getResultsDataFrame(low_memory=False)\n",
    "example_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e15c0a",
   "metadata": {},
   "source": [
    "As you can see in the results, there are some instances where study participants may have more than one value for a given variable. For example, this may be the case when a study participants answers questionnaires for multiple visits. \n",
    "\n",
    "In the PIC-SURE output, this is shown as values being separated by a tab or `\\t` value. These multiple values will need to be accounted for depending on the planned analysis.\n",
    "\n",
    "With this example, averages of the age and BMI values could be calculated and a new variable \"ever smoker\" could be created based on whether \"current smoker\" was ever answered for the CURSMOKE variable. The code below shows this example of how to handle these values.\n",
    "\n",
    "*Note: Approaches to handling multiple values will differ based on the approach.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows of interest and rename them\n",
    "clean_results = example_results[[\"\\\\tutorial-biolincc_framingham\\\\AGE\\\\\", \"\\\\tutorial-biolincc_framingham\\\\BMI\\\\\", \"\\\\tutorial-biolincc_framingham\\\\CURSMOKE\\\\\", \"\\\\tutorial-biolincc_framingham\\\\HYPERTEN\\\\\"]]\n",
    "clean_results.columns = [\"AGE\", \"BMI\", \"CURSMOKE\", \"HYPERTEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that splits the values and calculates the mean\n",
    "import statistics\n",
    "def mean_multiple_values(df_values):\n",
    "    sep_values = str(df_values).split(\"\\t\")\n",
    "    mean_val = statistics.mean([float(i) for i in sep_values])\n",
    "    return(mean_val)\n",
    "\n",
    "# Apply the function to calculate means to the AGE and BMI variables\n",
    "clean_results.loc[:, \"mean_age\"] = clean_results.loc[:, \"AGE\"].apply(mean_multiple_values)\n",
    "clean_results.loc[:, \"mean_bmi\"] = clean_results.loc[:, \"BMI\"].apply(mean_multiple_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbf696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that flags participants as smoker if they have an answer of \"Current smoker\"\n",
    "def ever_smoker(smoke_vals):\n",
    "    sep_smoke_vals = smoke_vals.split(\"\\t\")\n",
    "    if \"Current smoker\" in sep_smoke_vals:\n",
    "        return(\"Smoker\")\n",
    "    else:\n",
    "        return(\"Non-smoker\")\n",
    "    \n",
    "# Apply the function to identify smokers to the CURSMOKE variable\n",
    "clean_results.loc[:, \"ever_smoker\"] = clean_results.loc[:, \"CURSMOKE\"].apply(ever_smoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the new results\n",
    "clean_results[[\"mean_age\", \"mean_bmi\", \"ever_smoker\",\"HYPERTEN\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
